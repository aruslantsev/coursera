{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import datasets\n",
    "newsgroups = datasets.fetch_20newsgroups(subset='all',categories=['alt.atheism','sci.space'])\n",
    "#newsgroups.data newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5526315789473685\n",
      "{'C': 1e-05}\n",
      "0.5526315789473685\n",
      "{'C': 0.0001}\n",
      "0.5526315789473685\n",
      "{'C': 0.001}\n",
      "0.5526315789473685\n",
      "{'C': 0.01}\n",
      "0.9501679731243001\n",
      "{'C': 0.1}\n",
      "0.9932810750279956\n",
      "{'C': 1.0}\n",
      "0.9932810750279956\n",
      "{'C': 10.0}\n",
      "0.9932810750279956\n",
      "{'C': 100.0}\n",
      "0.9932810750279956\n",
      "{'C': 1000.0}\n",
      "0.9932810750279956\n",
      "{'C': 10000.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train=newsgroups.data\n",
    "Y_train=newsgroups.target\n",
    "tfv=sklearn.feature_extraction.text.TfidfVectorizer()\n",
    "X_train_tr=tfv.fit_transform(X_train)\n",
    "\n",
    "grid = {'C' : np.power(10.0, np.arange(-5, 5))}\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "clf = SVC (kernel='linear', random_state=241)\n",
    "gs = sklearn.model_selection.GridSearchCV(clf, grid, scoring='accuracy', cv=cv)\n",
    "gs.fit(X_train_tr, Y_train)\n",
    "for a in gs.grid_scores_ :\n",
    "    print(a.mean_validation_score)\n",
    "    print(a.parameters)\n",
    "C = gs.best_params_.get('C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['space', 'god', 'atheism', 'atheists', 'moon', 'sky', 'religion',\n",
      "       'bible', 'keith', 'sci'],\n",
      "      dtype='object')\n",
      "Index(['atheism', 'atheists', 'bible', 'god', 'keith', 'moon', 'religion',\n",
      "       'sci', 'sky', 'space'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'print_answer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-279b20e5de97>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint_answer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'print_answer' is not defined"
     ]
    }
   ],
   "source": [
    "clf = SVC (kernel='linear', random_state=241, C=C)\n",
    "clf.fit(X_train_tr, Y_train)\n",
    "words = tfv.get_feature_names()\n",
    "coef = pd.DataFrame(clf.coef_.data, clf.coef_.indices)\n",
    "top_words = coef[0].map(lambda w: abs(w)).sort_values(ascending=False).head(10).index.map(lambda i: words[i])\n",
    "print(top_words)\n",
    "print(top_words.sort_values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot sort an Index object in-place, use sort_values instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-91dbbab0e9a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0mtop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m \u001b[0mtop_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[0mprint_answer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m','\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36msort\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2547\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2548\u001b[1;33m         raise TypeError(\"cannot sort an Index object in-place, use \"\n\u001b[0m\u001b[0;32m   2549\u001b[0m                         \"sort_values instead\")\n\u001b[0;32m   2550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot sort an Index object in-place, use sort_values instead"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "import pandas\n",
    "import numpy as np\n",
    "from sklearn import datasets, grid_search\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "#from shad_util import print_answer\n",
    "\n",
    "# 1. Загрузите объекты из новостного датасета 20 newsgroups, относящиеся к категориям \"космос\" и\n",
    "# \"атеизм\" (инструкция приведена выше). Обратите внимание, что загрузка данных может занять несколько минут\n",
    "\n",
    "newsgroups = datasets.fetch_20newsgroups(subset='all', categories=['alt.atheism', 'sci.space'])\n",
    "X = newsgroups.data\n",
    "y = newsgroups.target\n",
    "\n",
    "# 2. Вычислите TF-IDF-признаки для всех текстов. Обратите внимание, что в этом задании мы предлагаем вам\n",
    "# вычислить TF-IDF по всем данным. При таком подходе получается, что признаки на обучающем множестве используют\n",
    "# информацию из тестовой выборки — но такая ситуация вполне законна, поскольку мы не используем значения целевой\n",
    "# переменной из теста. На практике нередко встречаются ситуации, когда признаки объектов тестовой выборки известны на\n",
    "# момент обучения, и поэтому можно ими пользоваться при обучении алгоритма.\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(X)\n",
    "\n",
    "# 3. Подберите минимальный лучший параметр C из множества [10^-5, 10^-4, ... 10^4, 10^5] для SVM с\n",
    "# линейным ядром (kernel='linear') при помощи кросс-валидации по 5 блокам. Укажите параметр random_state=241 и для SVM,\n",
    "# и для KFold. В качестве меры качества используйте долю верных ответов (accuracy).\n",
    "\n",
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "cv = KFold(y.size, n_folds=5, shuffle=True, random_state=241)\n",
    "model = SVC(kernel='linear', random_state=241)\n",
    "gs = grid_search.GridSearchCV(model, grid, scoring='accuracy', cv=cv)\n",
    "gs.fit(vectorizer.transform(X), y)\n",
    "\n",
    "C = gs.best_params_.get('C')\n",
    "\n",
    "# 4. Обучите SVM по всей выборке с оптимальным параметром C, найденным на предыдущем шаге.\n",
    "\n",
    "model = SVC(kernel='linear', random_state=241, C=C)\n",
    "model.fit(vectorizer.transform(X), y)\n",
    "\n",
    "# 5. Найдите 10 слов с наибольшим по модулю весом. Они являются ответом на это задание. Укажите их через запятую или\n",
    "# пробел, в нижнем регистре, в лексикографическом порядке.\n",
    "\n",
    "words = vectorizer.get_feature_names()\n",
    "coef = pandas.DataFrame(model.coef_.data, model.coef_.indices)\n",
    "top_words = coef[0].map(lambda w: abs(w)).sort_values(ascending=False).head(10).index.map(lambda i: words[i])\n",
    "top_words.sort()\n",
    "print_answer(1, ','.join(top_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['atheism', 'atheists', 'bible', 'god', 'keith', 'moon', 'religion',\n",
      "       'sci', 'sky', 'space'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(top_words.sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
