{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "34\n",
      "59\n",
      "64\n",
      "0.535\n",
      "0.5584415584415584\n",
      "0.4215686274509804\n",
      "0.48044692737430167\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn\n",
    "from sklearn.metrics import *\n",
    "\n",
    "data = pandas.read_csv('classification.csv')\n",
    "i = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "while (i < data.shape[0]):\n",
    "    if (data['true'][i]==data['pred'][i]):\n",
    "        if (data['pred'][i]==1):\n",
    "            tp = tp + 1\n",
    "        else:\n",
    "            tn = tn + 1\n",
    "    else:\n",
    "        if (data['pred'][i]==1):\n",
    "           fp = fp + 1\n",
    "        else:\n",
    "            fn = fn + 1\n",
    "    i = i + 1\n",
    "print(tp)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(tn)\n",
    "print(accuracy_score(data['true'], data['pred']))\n",
    "print(precision_score(data['true'], data['pred']))\n",
    "print(recall_score(data['true'], data['pred']))\n",
    "print(f1_score(data['true'], data['pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.719187675070028\n",
      "0.7086834733893557\n",
      "0.6351540616246498\n",
      "0.6919267707082833\n",
      "0.6302521008403361\n",
      "0.6228070175438597\n",
      "0.6065573770491803\n",
      "0.6517857142857143\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import sklearn\n",
    "from sklearn.metrics import *\n",
    "\n",
    "data = pandas.read_csv('scores.csv')\n",
    "print(roc_auc_score(data['true'], data['score_logreg']))\n",
    "print(roc_auc_score(data['true'], data['score_svm']))\n",
    "print(roc_auc_score(data['true'], data['score_knn']))\n",
    "print(roc_auc_score(data['true'], data['score_tree']))\n",
    "p1, r1, t1 = precision_recall_curve(data['true'], data['score_logreg'])\n",
    "p2, r2, t2 = precision_recall_curve(data['true'], data['score_svm'])\n",
    "p3, r3, t3 = precision_recall_curve(data['true'], data['score_knn'])\n",
    "p4, r4, t4 = precision_recall_curve(data['true'], data['score_tree'])\n",
    "\n",
    "p1m = 0\n",
    "p2m = 0\n",
    "p3m = 0\n",
    "p4m = 0\n",
    "for i in range(t1.size):\n",
    "    if ((r1[i] >= 0.7) and (p1[i] > p1m)):\n",
    "        p1m = p1[i]\n",
    "for i in range(t2.size):\n",
    "    if ((r2[i] >= 0.7) and (p2[i] > p2m)):\n",
    "        p2m = p2[i]\n",
    "for i in range(t3.size):\n",
    "    if ((r3[i] >= 0.7) and (p3[i] > p3m)):\n",
    "        p3m = p3[i]\n",
    "for i in range(t4.size):\n",
    "    if ((r4[i] >= 0.7) and (p4[i] > p4m)):\n",
    "        p4m = p4[i]\n",
    "print(p1m)\n",
    "print(p2m)\n",
    "print(p3m)\n",
    "print(p4m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
